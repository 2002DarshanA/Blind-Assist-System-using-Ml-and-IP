This project presents a Blind Assist System (BAS) leveraging Machine Learning (ML) and Image Processing (IP) techniques
to enhance the autonomy and safety of visually impaired individuals. The system utilizes a convolutionalneural network 
(CNN) to process real-time image inputs from a wearable camera device. Through ML classification, it identifies objects, 
obstacles, and environmental cues. The IP module further refines data, providing depth perception and spatial awareness. 
Leveraging ML's adaptability, the system continuously learns and improves its recognition accuracy. Integration with 
auditory feedback facilitates intuitive interaction, conveying vital information to users. In evaluations, the BAS demonstrates 
promising results in aiding navigation and increasing users' independence. The fusion of ML and IP offers a robust solution
for empowering the visually impaired in navigating complex environments.
